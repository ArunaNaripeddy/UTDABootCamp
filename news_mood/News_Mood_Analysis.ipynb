{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Mood Analysis\n",
    "---\n",
    "* From the scatterplot, it shows that NYTimes and CNN have more positive tweets based on Vader Sentiment Analysis. Whereas, CBS has a negative sentiment.\n",
    "* From bar graph, the average compound score for each media source is inline with the analysis from the scatterplot, which is NYtime, CNN having positive sentiments while CBS with negative sentiments. Fox and BBC around neutral.\n",
    "* Based on Vader Analysis, the choice of words in CNN and NYTimes tweets are more on the positive side whereas, the choice of words from CBS seems to be on the negative side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Dependencies\n",
    "* Tweepy API wrapper has been imported to interact with Twitter. And all the required modules numpy, pandas, matplotlib.pyplot and datetime have been imported.\n",
    "* Also, SentimentIntensityAnalyzer class has been loaded from vaderSentiment class.\n",
    "* Twitter API credentials has been stored in config.py and imported.\n",
    "* Twitter OAuth authentication has been setup using tweepy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Twitter API Keys\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis - Media Sources\n",
    "---\n",
    "Sentiment analysis for media sources- BBCNews, CBSNews, CNN, FoxNews, NYTimes is done for the latest 100 tweets. Pagination is handled by initializing 'max_id' with the oldest 'tweet id'. The sentiment analysis results (positive, negative,neutral and compund scores) are saved as a list of dictionaries. And a counter has been created to keep track of number of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Accounts\n",
    "target_user = (\"@BBCNews\", \"@CBSNews\", \"@CNN\", \"@FoxNews\", \"@nytimes\")\n",
    "\n",
    "# Variables for holding sentiments\n",
    "sentiments = []\n",
    "\n",
    "# Looping through each target user\n",
    "for target in target_user:\n",
    "    # Variable for max_id\n",
    "    oldest_tweet = None\n",
    "    # Counter\n",
    "    counter = 1\n",
    "    \n",
    "    # Loop through 5 pages of tweets (total 100 tweets)\n",
    "    for x in range(5):\n",
    "\n",
    "        # Get all tweets from home feed\n",
    "        public_tweets = api.user_timeline(target, max_id = oldest_tweet)\n",
    "\n",
    "        # Loop through all tweets \n",
    "        for tweet in public_tweets:\n",
    "            \n",
    "            # Run Vader Analysis on each tweet\n",
    "            results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "            compound = results[\"compound\"]\n",
    "            pos = results[\"pos\"]\n",
    "            neu = results[\"neu\"]\n",
    "            neg = results[\"neg\"]\n",
    "            tweets_ago = counter\n",
    "\n",
    "            # Get Tweet ID, subtract 1, and assign to oldest_tweet\n",
    "            oldest_tweet = tweet['id'] - 1\n",
    "\n",
    "            # Add sentiments for each tweet into a list\n",
    "            sentiments.append({\"Media Source\": target,\n",
    "                               \"Tweet Text\": tweet[\"text\"],\n",
    "                               \"Date\": tweet[\"created_at\"], \n",
    "                               \"Compound\": compound,\n",
    "                               \"Positive\": pos,\n",
    "                               \"Negative\": neu,\n",
    "                               \"Neutral\": neg,\n",
    "                               \"Tweets Ago\": counter})\n",
    "\n",
    "            # Add to counter \n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiments Dataframe\n",
    "Dataframe is created from list of sentiment dicitonaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiments to DataFrame\n",
    "sentiments_pd = pd.DataFrame.from_dict(sentiments)\n",
    "\n",
    "columns = [\"Media Source\", \"Date\", \"Tweet Text\", \"Compound\", \"Positive\", \"Negative\", \"Neutral\", \"Tweets Ago\"]\n",
    "sentiments_pd = sentiments_pd[columns]\n",
    "\n",
    "# Printing the sentiments dataframe\n",
    "sentiments_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the dataframe to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_pd.to_csv(\"News_Mood_Analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the sentiment records from the dataframe based on type of Media source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc = sentiments_pd.loc[sentiments_pd[\"Media Source\"] == \"@BBCNews\"]\n",
    "cnn = sentiments_pd.loc[sentiments_pd[\"Media Source\"] == \"@CNN\"]\n",
    "cbs_news = sentiments_pd.loc[sentiments_pd[\"Media Source\"] == \"@CBSNews\"]\n",
    "fox_news = sentiments_pd.loc[sentiments_pd[\"Media Source\"] == \"@FoxNews\"]\n",
    "nytimes = sentiments_pd.loc[sentiments_pd[\"Media Source\"] == \"@nytimes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot\n",
    "---\n",
    "Generate a scatter plot for compound sentiment score versus number of tweets for each media source listed. Matplotlib.pyplot library is used for plotting the scatter plot. All the required aesthetics of the plot are handled along with the plot legend. Before calling the plot.show(), the image has been saved to a .PNG file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(bbc[\"Tweets Ago\"],\n",
    "            bbc[\"Compound\"], \n",
    "            c=\"lightblue\",\n",
    "            s=100,\n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"BBC\")\n",
    "\n",
    "plt.scatter(cbs_news[\"Tweets Ago\"],\n",
    "            cbs_news[\"Compound\"], \n",
    "            c=\"green\", \n",
    "            s=100,\n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"CBS\")\n",
    "\n",
    "plt.scatter(cnn[\"Tweets Ago\"],\n",
    "            cnn[\"Compound\"], \n",
    "            c=\"red\", \n",
    "            s=100,\n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"CNN\")\n",
    "\n",
    "plt.scatter(fox_news[\"Tweets Ago\"],\n",
    "            fox_news[\"Compound\"], \n",
    "            c=\"purple\", \n",
    "            s=100,\n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"Fox\")\n",
    "\n",
    "plt.scatter(nytimes[\"Tweets Ago\"],\n",
    "            nytimes[\"Compound\"], \n",
    "            c=\"gold\",\n",
    "            s=100,\n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"New York Times\")\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "x_vals = cnn[\"Tweets Ago\"]\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "plt.title(f\"Sentiment Analysis of Media Tweets ({now})\")\n",
    "plt.xlim([x_vals.max()+5, x_vals.min()-5]) \n",
    "plt.ylim([-1.1, 1.1])\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "\n",
    "lgnd = plt.legend(loc=\"center right\", fontsize=\"large\", title=\"Media Sources\", \n",
    "                  bbox_to_anchor=(0.5, 0.5, 0.9, 0.5))\n",
    "lgnd.get_title().set_fontsize(\"15\")\n",
    "lgnd.legendHandles[0]._sizes = [100]\n",
    "lgnd.legendHandles[1]._sizes = [100]\n",
    "lgnd.legendHandles[2]._sizes = [100]\n",
    "lgnd.legendHandles[3]._sizes = [100]\n",
    "lgnd.legendHandles[4]._sizes = [100]\n",
    "\n",
    "ax.set_yticks(np.arange(-1.0,1.5,0.5))\n",
    "plt.grid(True)\n",
    "\n",
    "# Save Figure\n",
    "plt.savefig(\"analysis/news_mood_scatter_plot.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Sentiment  Analysis\n",
    "Average compound score is calculated for each media source and added to a list of dictionaries. Then create a dataframe from the overall sentiment analysis list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Averages\n",
    "overall_sentiment_list = []\n",
    "for target in target_user:\n",
    "   # Create a dictionaty of results\n",
    "    media_source_df = sentiments_pd.loc[sentiments_pd[\"Media Source\"] == target]\n",
    "    aggregate_dict = {\n",
    "        \"Media Source\": target,\n",
    "        \"Compound Score\": np.mean(media_source_df[\"Compound\"]),\n",
    "    }\n",
    "    overall_sentiment_list.append(aggregate_dict)\n",
    "\n",
    "overall_sentiment_df = pd.DataFrame(overall_sentiment_list).round(3)\n",
    "overall_sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Plot\n",
    "Bar plot has been plotted for Compound sentiment score versus media source. And the aesthetics for the bar plot are defined.\n",
    "After creating the plot, save the plot to a .PNG file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array that contains the overall compound sentiment score\n",
    "x_axis = np.arange(len(overall_sentiment_df))\n",
    "tick_locations = [value for value in x_axis]\n",
    "\n",
    "fig1 = plt.figure(figsize=(8,5))\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "\n",
    "colors = [\"cyan\",\"green\", \"red\", \"darkblue\", \"gold\"]\n",
    "plt.bar(x_axis, overall_sentiment_df[\"Compound Score\"],\n",
    "        color=colors, alpha=0.5, width=1.0, align=\"center\")\n",
    "\n",
    "plt.xticks(tick_locations, overall_sentiment_df[\"Media Source\"])\n",
    "ax1.set_xticklabels((\"BBC\", \"CBS\", \"CNN\", \"FOX\", \"NYT\"))\n",
    "ax1.set_yticks(np.arange(overall_sentiment_df[\"Compound Score\"].min()-0.01, \n",
    "                        overall_sentiment_df[\"Compound Score\"].max()+0.01,\n",
    "                        0.05))\n",
    "\n",
    "# Set x and y limits\n",
    "plt.xlim(-0.75, len(x_axis)-0.25)\n",
    "plt.ylim([overall_sentiment_df[\"Compound Score\"].min()-0.03, overall_sentiment_df[\"Compound Score\"].max()+0.01])\n",
    "\n",
    "# Set a Title and labels\n",
    "plt.title(f\"Overall Media Sentiment based on Twitter ({now})\")\n",
    "plt.xlabel(\"Media Source\", fontsize=15)\n",
    "plt.ylabel(\"Tweet Polarity\", fontsize=15)\n",
    "\n",
    "# set individual bar lables using above list\n",
    "for i in ax1.patches:\n",
    "    # get_x pulls left or right; get_height pushes up or down\n",
    "    ax1.text(i.get_x()+.35, i.get_height()-0.01,\\\n",
    "            str(round((i.get_height()), 2)), fontsize=11, color=\"black\")\n",
    "\n",
    "# Save graph and show\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.savefig(\"analysis/overall_sentiment_analysis.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
